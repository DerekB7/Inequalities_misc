{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex 1.49 in Korner's *A Companion to Analysis*  (page 21)  \n",
    "part (ii) is of considerable interest    \n",
    "because it allows us recover mean value inequality based on using compactness to prove an increasing function...   \n",
    "\n",
    "In terms of technique, there approach used here reminds your author of the technique used in ex 6.10 of *Cauchy Schwarz Masterclass*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in some open set $(\\alpha, \\beta) \\in \\mathbb R$, supposing $K\\geq 0$ and that $a,b \\in U$ with $b \\gt a$ if \n",
    "$f: U\\longrightarrow \\mathbb R$ is differentiable with $f'(t) \\leq K$ for all $t \\in U$, then  \n",
    "\n",
    "$f(b) - f(a) \\leq (b-a)K$  \n",
    "*this is the mean value inequality*  \n",
    "\n",
    "\n",
    "(ii)  \n",
    "we are to show that the mean value inequality is implied by  \n",
    "in some open set $(\\alpha, \\beta) \\in \\mathbb R$, supposing $K\\geq 0$ and that $a,b \\in U$ with $b \\gt a$ if \n",
    "$g: U\\longrightarrow \\mathbb R$ is differentiable with $f'(t) \\geq 0 $ for all $t \\in U$, then\n",
    "\n",
    "$0 \\leq g(b) - g(a) $  \n",
    "This result can be proven independently via compactness / extreme value theorem arguments (see below cells).  \n",
    "\n",
    "that is, if we select \n",
    "\n",
    "$g(t):= Kt - f(t)$  \n",
    "observing that  \n",
    "$g'(t):= K - f'(t)\\geq 0$  \n",
    "where as before we assume $f'(t) \\leq K$  \n",
    "hence we know  $0 \\leq g(b) - g(a) $  holds  \n",
    "\n",
    "then compute the difference:  \n",
    "$0 \\leq g(b) -g(a)= Kb - f(b) - \\big( Ka - f(a)\\big)  = K(b-a) - f(b) + f(a) $  \n",
    "or  \n",
    "$f(b) - f(a) \\leq  K(b-a) $  \n",
    "\n",
    "- - - - -  \n",
    "a *slightly* different approach would be to make a nicer argument using a strict inequality, so for any $\\epsilon \\gt 0$  \n",
    "and any $K \\gt 0$  \n",
    "\n",
    "$g(t):= (1+\\epsilon) Kt - f(t)$  \n",
    "which implies $g'(t) \\gt 0$  \n",
    "and hence  \n",
    "\n",
    "$0 \\lt g(b) -g(a)= (1+\\epsilon) K(b-a) - f(b) + f(a) $  \n",
    "\n",
    "or  \n",
    "\n",
    "$f(b) - f(a) \\lt (1+\\epsilon) K(b-a)  $  \n",
    "or  \n",
    "$f(b) - f(a) \\leq K(b-a)  $  \n",
    "as desired  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**proof that positive first deriviative implies increasing function**  \n",
    "\n",
    "since $\\alpha \\lt a \\lt b \\lt \\beta$  \n",
    "and the function $g$ is differentiable in this open set, with strictly positive derivative, it is enough to consider the mapping  \n",
    "\n",
    "$g: \\big[a,b\\big] \\longrightarrow [\\text{minimum}, \\text{maximum}]$  \n",
    "\n",
    "our interest is in the minimum value taken on by the function over this closed interval.  \n",
    "\n",
    "It's enough to consider two cases:  either\n",
    "\n",
    "$\\text{(1)} g(a) \\lt g(x)$ for $x \\in (a,b]$  i.e. the left boundary is mapped to the the unique minimum in this closed set   \n",
    "$\\text{(2)}$ there is (at least one) $x^* \\in(a,b]$ where $ g(x^*) \\leq g(x)$ for all $x \\in [a,b]$. \n",
    "\n",
    "In the case of $\\text{(i)}$ everything works as desired.  \n",
    "\n",
    "But $\\text{(2)}$ isn't true so we can proceed by contradiction:  \n",
    "Consider the left difference quotients at $g(x^*)$ we know they converge to $g'(x^*) = c \\gt 0$  \n",
    "From here select select $\\epsilon := \\frac{c}{2}$ and we find a contradiction if $g(x^*)$ is a minimum because for any (sufficientlty small) $\\delta \\gt 0$  \n",
    "\n",
    "$\\frac{g(x^* - \\delta) - g(x^*)}{(x^* - \\delta) - x^*)}= \\frac{ g(x^*)- g(x^* - \\delta) }{ \\delta)} \\leq  \\frac{ 0 }{ \\delta}=0  $  \n",
    "\n",
    "i.e. it can never be in the required neighborhood of \n",
    "\n",
    "$\\big(\\frac{1}{2}c, \\frac{3}{2}c\\big)$  \n",
    "\n",
    "and hence \n",
    "\n",
    "$g'(x^*) = \\lim_{x\\to (x^*)^{-}} \\frac{g(x)- g(x^*)}{x-x^*}$  \n",
    "does not exist.  But if the left limit does not exist, then the function is not differentiable at that point, which contradicts the fact that $g$ is differentiable in $(\\alpha, \\beta)$  \n",
    "\n",
    "\n",
    "\n",
    "and hence the sequence doesn't converge and the derivative does not exist -- a contradiction.  \n",
    "\n",
    "For avoidance of doubt:  the fact the $g$ is differentiable implies it is continuous, which combined with compactness guarantees a minimum value of $g$ in this $[a,b]$, thus we must have $\\text{(2)}$ \n",
    "\n",
    "note that the choices of $a,b$ were arbitrary so we may infer that for any $x_1, x_2 \\in (\\alpha, \\beta)$, if $x_1 \\lt x_2$ then $g(x_1) \\lt g(x_2)$ -- i.e. $g$ is strictly increasing whenever its derivative is positive.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**proof that non-negative first deriviative implies non-decreasing function**  \n",
    "\n",
    "To accomodate the weaker case of $g'(t)\\geq 0$ over $(\\alpha, \\beta)$ again consider $\\alpha \\lt a \\lt b \\lt \\beta$  \n",
    "\n",
    "$g: \\big[a,b\\big] \\longrightarrow [\\text{minimum}, \\text{maximum}]$  \n",
    "\n",
    "our interest is in the minimum value taken on by the function over this closed interval.  \n",
    "\n",
    "This time consider \n",
    "\n",
    "$\\text{(1)} g(a) \\leq g(x)$ for $x \\in (a,b]$  i.e. the left boundary is mapped to the the not necessiarily minimum in this closed set   \n",
    "$\\text{(2)}$ there is (at least one) $x^* \\in(a,b]$ where $g(x^*) \\lt g(a)$ for all $x \\in [a,b]$, or equivalently  \n",
    "$\\gamma = \\text{minimum} \\lt g(a)$  \n",
    "\n",
    "as before there is no problem with $\\text{(1)}$ but $\\text{(2)}$ is wrong so proceed by contradiction.\n",
    "define  \n",
    "$x^* := \\text{inf x:   } g(x) = \\gamma = \\text{min x :  } g(x) = \\gamma$.  \n",
    "\n",
    "Note that the infimum must exist in $(a,b]$ but by continuity the preimage of points mapped to $\\gamma$ must have a minimum (i.e. left closed interval that is a lower bound--  if it didn't e.g. the function achieved the minimum at say $(x, \\text{__}]$  then $g(x^*) - g(x^*) = c \\gt 0$, selecting $\\epsilon := \\frac{c}{2}$ gets us a contradiction because there is no $\\delta \\gt 0$ such that \n",
    "$g\\big(N(x, \\delta)\\big) \\subseteq N\\big(g(x),\\epsilon\\big)$ and hence the function is not continuous at $x$ which contradicts $g$ being not only continuous but differentiable at that point).  \n",
    "\n",
    "However if we compute the left derivative at $x^*$ we have \n",
    "\n",
    "for any sufficiently small $\\delta \\gt 0$  \n",
    "$\\frac{g(x^*-\\delta) -g(x^*)}{-\\delta}  = \\frac{g(x^*) - g(x^*-\\delta)}{\\delta}\\lt   \\frac{0}{\\delta} = 0$  \n",
    "which contradicts the fact that the limit exists and $g(x^*) \\geq 0$  \n",
    "\n",
    "Thus as before, since we know a minimum value exists (continuous functions map compact sets to compact sets afterall) so  $(1)$ must be true, and in particular $g(a) \\leq g(b)$, and as above we recall that the selection of $a\\lt b$ was arbitrary hence the function must be non-decreasing over $U$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice corollary given on page 20 of Korner -- The Constant Value Theorem-- is that if $U:= (\\alpha, \\beta)$ and  \n",
    "$f: U \\to \\mathbb R$ is differentiable and $f'(t) = 0$ for all $t \\in U$ then $f$ is constant.  \n",
    "\n",
    "in particular we apply mean value inequality one way to see, with $K=0$, for $a, b \\in U$ and $b \\gt a$  \n",
    "\n",
    "$f(b) - f(a) \\leq K(b-a) = 0(b-a) = 0$  \n",
    "or  \n",
    "\n",
    "$f(b) \\leq f(a)$  \n",
    "\n",
    "and we also apply it to $-f$, which still has the constant derivative equal to zero, to get  \n",
    "\n",
    "$f(a)  -f(b)  -f(b) - -f(a) \\leq K(b-a) = 0(b-a) = 0$  \n",
    "or \n",
    "$f(a) \\leq f(b)$  \n",
    "\n",
    "hence $f(a) = f(b)$  \n",
    "\n",
    "but the selection of $a,b$ was arbitrary hence we see that any and all 2 points in $U$ must have the same value under the image of $f$.  \n",
    "- - - - -  \n",
    "Another corollary is that  \n",
    "if two differentiable functions $f$, $g$ have the same derivative at all points in $U$ then $f(x) = g(x) + c$.  The proof comes from considering the function $h(x) = f(x) - g(x)$ which has a derivative of zero everywhere in $U$.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then do the complex variables exercise of mean value on page 274, and possibly multidimensional one on page 131-132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
